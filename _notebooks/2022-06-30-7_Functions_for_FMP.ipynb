{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f47b3c0b",
   "metadata": {},
   "source": [
    "# 7) FUNCIONES DESARROLLADAS PARA EL PROYECTO\n",
    "\n",
    "> En este notebook se encuentran todas las funciones utilizadas a lo largo de los distintos bloques del proyecto.\n",
    "\n",
    "- author: Iván Fernández Aguirre\n",
    "- toc: true\n",
    "- image: images/N7.png\n",
    "- sticky_rank: 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41beb29",
   "metadata": {},
   "source": [
    "## FUNCIONES GENERALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "061f0088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139829b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b58a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(DF,List):\n",
    "    '''\n",
    "    Cambia nombre de columnas de un Dataframe\n",
    "    \n",
    "    Arguments:\n",
    "        DF: DataFrame\n",
    "        List: Lista con nombres de columnas\n",
    "    '''\n",
    "    d=dict(zip(list(DF.columns),List))\n",
    "    DF.rename(columns=d, inplace=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28568d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_NaNs(D):\n",
    "    '''\n",
    "    Verifica los missing values en un Dataframe\n",
    "    \n",
    "    Arguments:\n",
    "        D: Dataframe\n",
    "    '''\n",
    "    l=len(D)\n",
    "    t=0\n",
    "    for c in D.columns:\n",
    "        n=D[c].isna().sum()  \n",
    "        t=t+n\n",
    "        if(n>0):\n",
    "            print(c,'  Nulls: {} / {} - {}%'.format(n,l,np.round(100*n/l,2)))\n",
    "    if(t>0):\n",
    "        print('\\ntotal missing values: {}'.format(t))\n",
    "    else:\n",
    "        print('No hay missing values en el dataset :)')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b48cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Print_features(DF):\n",
    "    '''\n",
    "    Imprime por pantalla los Features del dataset FMP, hasta el nootebook 4\n",
    "    \n",
    "    Arguments:\n",
    "        DF: Dataframe\n",
    "    '''\n",
    "    print('Today Features\\n')\n",
    "    for c in DF.columns:\n",
    "        if ( not(bool(re.search(r'\\d', c)))):\n",
    "            print(c)\n",
    "\n",
    "    print('\\n\\nHistoric Features\\n')\n",
    "    for c in DF.columns:\n",
    "        if ( ('1' in c) and (not('0' in c)) and ('home' in c) and (not('away' in c)) ):\n",
    "            print('home/away'+c[4:-1]+'i')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c713a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Print_features_data_set_modelos(DF):\n",
    "    '''\n",
    "    Imprime por pantalla los Features del dataset FMP, para el nootebook 5\n",
    "    \n",
    "    Arguments:\n",
    "        DF: Dataframe\n",
    "    '''\n",
    "    print('Today Features\\n')\n",
    "    for c in DF.columns:\n",
    "        if ( not(bool(re.search(r'\\d', c)))):\n",
    "            print(c)\n",
    "\n",
    "    print('\\n\\nHistoric Features\\n')\n",
    "    for c in DF.columns:\n",
    "        if ( ('1' in c) and (not('0' in c)) and ('Equipo_A' in c) and (not('Equipo_B' in c)) ):\n",
    "            print('Equipo_(A/B)'+c[8:-1]+'i')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c132419e",
   "metadata": {},
   "source": [
    "## VISULAIZACIÓN Y EXPLORACIÓN DEL *DATASET*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7ad39",
   "metadata": {},
   "source": [
    "### Distribuciones de probabilidad e histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41b8682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skellam, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a4c0bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Poisson_distribution(x,l):\n",
    "    '''\n",
    "    Forma analítica de la distribución de Poisson \n",
    "    \n",
    "    Arguments:\n",
    "        l: Lambda\n",
    "    \n",
    "    Returns:\n",
    "        array transformado\n",
    "    '''\n",
    "    fact=np.vectorize(np.math.factorial, otypes='O')\n",
    "    return (l**x)*np.exp(-l)/fact(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77103f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Log_normal(x,m,s):\n",
    "    '''\n",
    "    Forma analítica de la distribución de Log-normal\n",
    "    \n",
    "    Arguments:\n",
    "        m: media\n",
    "        s: desviación estandar\n",
    "    \n",
    "    Returns:\n",
    "        array transformado\n",
    "    '''\n",
    "    return (1.0/(x*s*np.math.sqrt(2*np.pi)))*np.exp(-((np.log(x)-m)**2)/(2*(s**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "083dcf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_distributions(DS,columns,rows,Features,Type,n_bin,Dist,x_label,y_label,alig):\n",
    "    '''\n",
    "    Grafica histogramas de features de un DataFrame. Calcula: media, std, std error, skewness, entre otros.\n",
    "    Si se propone una distribución entre las disponibles (Log-norm, Poisson, Normal, Skellam), \n",
    "    la grafica tomando los valores del histograma.\n",
    "    \n",
    "    Arguments:\n",
    "        DS: DataFrame\n",
    "        columns: numero de columnas de la figura\n",
    "        rows: numerod de filas de la figura\n",
    "        Features: Lista de Features a analizar\n",
    "        Type: tipo de dato 'historic' or 'match'\n",
    "        n_bin: Lista con numero de bines del histograma\n",
    "        Dist: Lista con Distribución a graficar.\n",
    "        x_label: Lista con nombre del x label de cada subplot\n",
    "        y_label: Lista con nombre del y label de cada subplot\n",
    "        alig: alineacion de las barras del histograma 'mid' 'left' or 'right'\n",
    "\n",
    "    '''\n",
    "    fig, a = plt.subplots(nrows=rows, ncols=columns)\n",
    "    if(columns*rows==1):\n",
    "        a=[a]\n",
    "    for ax,f,t,b,d,xl,yl,al in zip(a,Features,Type,n_bin,Dist,x_label,y_label,alig):\n",
    "        if(t=='historic'):\n",
    "            C=[t+'_'+f+'_'+str(i) for t in ['home','away'] for i in range(1,11)]\n",
    "        elif(t=='match'):\n",
    "            C=[f]\n",
    "        X=DS[C].to_numpy()\n",
    "        X=np.reshape(X, (np.size(X),1))\n",
    "        m=np.nanmean(X)\n",
    "        std=np.nanstd(X)\n",
    "        me=np.nanmedian(X)\n",
    "        sk=3*(m-me)/std\n",
    "        mx=np.nanmax(X)\n",
    "        mn=np.nanmin(X)\n",
    "        n=np.sum(~np.isnan(X))\n",
    "        H =ax.hist(X, bins=b,density=True,align=al, alpha=0.9)\n",
    "        if(Dist=='Unknown'):\n",
    "            textstr = '\\n'.join((\n",
    "                r'$\\mu=%.3f$' % (m, ),\n",
    "                r'max$=%.2f$' % (mx, ),\n",
    "                r'min$=%.2f$' % (mn, ),\n",
    "                r'$\\mathrm{median}=%.2f$' % (me, ),\n",
    "                r'$\\sigma=%.2f$' % (std, ),\n",
    "                r'pearson skewness$=%.2f$' % (sk, ),\n",
    "                r'n$=%.0f$' % (n, ),\n",
    "                r'std error$=%.3f$' % (std/np.math.sqrt(n), )))\n",
    "        else:\n",
    "            textstr = '\\n'.join((\n",
    "                r'$\\mu=%.3f$' % (m, ),\n",
    "                r'max$=%.2f$' % (mx, ),\n",
    "                r'min$=%.2f$' % (mn, ),\n",
    "                r'$\\mathrm{median}=%.2f$' % (me, ),\n",
    "                r'$\\sigma=%.2f$' % (std, ),\n",
    "                r'pearson skewness$=%.2f$' % (sk, ),\n",
    "                r'n$=%.0f$' % (n, ),\n",
    "                r'std error$=%.3f$' % (std/np.math.sqrt(n), ),\n",
    "                r'pdf utilizada$:$ '+d))\n",
    "        \n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "        ax.text(0.65, 0.95, textstr, transform=ax.transAxes, fontsize=16,verticalalignment='top', bbox=props)\n",
    "        if (d!='Unknown'):\n",
    "            if(d=='Poisson'):\n",
    "                B=np.arange(mn,mx+1)\n",
    "                ax.plot(B,Poisson_distribution(B,m),color='orange',lw=2)\n",
    "            elif(d=='Log-norm'):\n",
    "                B=np.linspace(mn,mx,1000)\n",
    "                m_l=np.math.log(m**2/(np.math.sqrt(m**2+std*2)))\n",
    "                std_l=np.math.sqrt(np.math.log(1+((std**2)/(m**2))))\n",
    "                ax.plot(B,Log_normal(B,m_l,std_l),color='orange',lw=2)\n",
    "            elif(Dist=='Skellam'):\n",
    "                mu1=(std*2+m)/2\n",
    "                mu2=(std*2-m)/2\n",
    "                B=np.arange(mn,mx+1)\n",
    "                ax.plot(B,skellam.pmf(B,mu1,mu2),color='orange',lw=2)\n",
    "            elif(Dist=='Normal'):\n",
    "                B=np.linspace(mn,mx,1000)\n",
    "                ax.plot(B,norm.pdf(B, m, std),color='orange',lw=2)\n",
    "        ax.set_ylabel(yl,fontsize=20)\n",
    "        ax.set_xlabel(xl,fontsize=20)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    fig.set_size_inches(20,5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab55c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_one_distribution(DS,Features,Type,n_bin,Dist,x_label,y_label,al,text_x_pos=0.65,xlim=(None,None)):\n",
    "    '''\n",
    "    Grafica el histograma para una featuree de un DataFrame. Calcula: media, std, std error, skewness, entre otros.\n",
    "    Si se propone una distribución entre las disponibles (Log-norm, Poisson, Normal, Skellam), \n",
    "    la grafica tomando los valores del histograma.\n",
    "    \n",
    "    Arguments:\n",
    "        DS: DataFrame\n",
    "        Feature: Feature a analizar\n",
    "        Type: tipo de dato 'historic' or 'match'\n",
    "        n_bin: Lista con numero de bines del histograma\n",
    "        Dist: Lista con Distribución a graficar.\n",
    "        x_label: Lista con nombre del x label de cada subplot\n",
    "        y_label: Lista con nombre del y label de cada subplot\n",
    "        al: alineacion de las barras del histograma 'mid' 'left' or 'right'\n",
    "        text_box_pos: posicion [x,y] del cuadro de texto\n",
    "        xlim: rango en x\n",
    "\n",
    "    '''\n",
    "    fig, ax = plt.subplots()\n",
    "    C=[]\n",
    "    for f,t in zip(Features,Type):\n",
    "        if(t=='historic'):\n",
    "            C=C+[t+'_'+f+'_'+str(i) for t in ['home','away'] for i in range(1,11)]\n",
    "        elif(t=='match'):\n",
    "            C=C+[f]\n",
    "    X=DS[C].to_numpy()\n",
    "    X=np.reshape(X, (np.size(X),1))\n",
    "    m=np.nanmean(X)\n",
    "    std=np.nanstd(X)\n",
    "    me=np.nanmedian(X)\n",
    "    sk=3*(m-me)/std\n",
    "    mx=np.nanmax(X)\n",
    "    mn=np.nanmin(X)\n",
    "    n=np.sum(~np.isnan(X))\n",
    "    H =ax.hist(X, bins=n_bin,density=True,align=al, alpha=0.9)\n",
    "    if (Dist=='Unknown'):\n",
    "        textstr = '\\n'.join((\n",
    "            r'$\\mu=%.3f$' % (m, ),\n",
    "            r'max$=%.2f$' % (mx, ),\n",
    "            r'min$=%.2f$' % (mn, ),\n",
    "            r'$\\mathrm{median}=%.2f$' % (me, ),\n",
    "            r'$\\sigma=%.2f$' % (std, ),\n",
    "            r'pearson skewness$=%.2f$' % (sk, ),\n",
    "            r'n$=%.0f$' % (n, ),\n",
    "            r'std error$=%.3f$' % (std/np.math.sqrt(n), )))\n",
    "    else:\n",
    "        textstr = '\\n'.join((\n",
    "            r'$\\mu=%.3f$' % (m, ),\n",
    "            r'max$=%.2f$' % (mx, ),\n",
    "            r'min$=%.2f$' % (mn, ),\n",
    "            r'$\\mathrm{median}=%.2f$' % (me, ),\n",
    "            r'$\\sigma=%.2f$' % (std, ),\n",
    "            r'pearson skewness$=%.2f$' % (sk, ),\n",
    "            r'n$=%.0f$' % (n, ),\n",
    "            r'std error$=%.3f$' % (std/np.math.sqrt(n), ),\n",
    "            r'pdf utilizada$:$ '+Dist))\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    ax.text(text_x_pos, 0.95, textstr, transform=ax.transAxes, fontsize=11,verticalalignment='top', bbox=props)\n",
    "    if (Dist!='Unknown'):\n",
    "        if(Dist=='Poisson'):\n",
    "            B=np.arange(mn,mx+1)\n",
    "            ax.plot(B,Poisson_distribution(B,m),color='orange',lw=2)\n",
    "        elif(Dist=='Log-norm'):\n",
    "            B=np.linspace(mn,mx,1000)\n",
    "            m_l=np.math.log(m**2/(np.math.sqrt(m**2+std*2)))\n",
    "            std_l=np.math.sqrt(np.math.log(1+((std**2)/(m**2))))\n",
    "            ax.plot(B,Log_normal(B,m_l,std_l),color='orange',lw=2)\n",
    "        elif(Dist=='Skellam'):\n",
    "            mu1=(std*2+m)/2\n",
    "            mu2=(std*2-m)/2\n",
    "            B=np.arange(mn,mx+1)\n",
    "            ax.plot(B,skellam.pmf(B,mu1,mu2),color='orange',lw=2)\n",
    "        elif(Dist=='Normal'):\n",
    "            B=np.linspace(mn,mx,1000)\n",
    "            ax.plot(B,norm.pdf(B, m, std),color='orange',lw=2)\n",
    "    ax.set_ylabel(y_label,fontsize=16)\n",
    "    ax.set_xlabel(x_label,fontsize=16)\n",
    "    plt.xticks(fontsize=13)\n",
    "    plt.yticks(fontsize=13)\n",
    "    if(xlim[0]!=None):\n",
    "        ax.set_xlim(xlim)\n",
    "    fig.set_size_inches(12,5)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d213a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_distribution_por_Condicion_team_and_opp(DS,Features_Team,Features_Opponent,Condition,Cond_Labels,n_bin,Dist,x_label,y_label,al,Text_box_pos=[0.4,0.7]):\n",
    "    '''\n",
    "    Grafica dos histogramas de una feature en función de una condicion donde sumamos datos historicos de equipos y oponentes.\n",
    "    Calcula: media, std, std error, skewness, entre otros. Si se propone una distribución entre las disponibles (Log-norm, Poisson, Normal, Skellam), \n",
    "    la grafica tomando los valores del histograma.\n",
    "    \n",
    "    Arguments:\n",
    "        DS: DataFrame\n",
    "        Features_team: Feature a analizar (team)\n",
    "        Features_Opponent: Feature a analizar (historic opponent)\n",
    "        Condition: Condicion (variable true or False) que separa los datos\n",
    "        Condition_Labels: Que representa True y False\n",
    "        Type: tipo de dato 'historic' or 'match'\n",
    "        n_bin: Lista con numero de bines del histograma\n",
    "        Dist: Lista con Distribución a graficar.\n",
    "        x_label: Lista con nombre del x label de cada subplot\n",
    "        y_label: Lista con nombre del y label de cada subplot\n",
    "        al: alineacion de las barras del histograma 'mid' 'left' or 'right'\n",
    "        text_box_pos: posicion [x,y] del cuadro de texto\n",
    "        xlim: rango en x\n",
    "\n",
    "    '''\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    Local=np.array([])\n",
    "    Visitante=np.array([])\n",
    "    for t in ['home','away']:\n",
    "        C=[t+'_'+Condition+'_'+str(i) for i in range(1,11)]\n",
    "        fil=DS[C].to_numpy()\n",
    "        fil=np.reshape(fil, (np.size(fil),1)).astype('bool')\n",
    "        F=[t+'_'+Features_Team+'_'+str(i) for i in range(1,11)]\n",
    "        G=DS[F].to_numpy()\n",
    "        G=np.reshape(G, (np.size(G),1))\n",
    "        \n",
    "        Local=np.concatenate((Local,G[fil]))\n",
    "        Visitante=np.concatenate((Visitante,G[~fil]))\n",
    "    \n",
    "    for t in ['home','away']:\n",
    "        C=[t+'_'+Condition+'_'+str(i) for i in range(1,11)]\n",
    "        fil=DS[C].to_numpy()\n",
    "        fil=np.reshape(fil, (np.size(fil),1)).astype('bool')\n",
    "        F=[t+'_'+Features_Opponent+'_'+str(i) for i in range(1,11)]\n",
    "        G=DS[F].to_numpy()\n",
    "        G=np.reshape(G, (np.size(G),1))\n",
    "        \n",
    "        Local=np.concatenate((Local,G[~fil]))\n",
    "        Visitante=np.concatenate((Visitante,G[fil]))\n",
    "        \n",
    "    \n",
    "    for X,n,p,b,c in zip([Local,Visitante],Cond_Labels,Text_box_pos,n_bin,['k','r']):\n",
    "        m=np.nanmean(X)\n",
    "        std=np.nanstd(X)\n",
    "        me=np.nanmedian(X)\n",
    "        sk=3*(m-me)/std\n",
    "        mx=np.nanmax(X)\n",
    "        mn=np.nanmin(X)\n",
    "        nn=np.sum(~np.isnan(X))\n",
    "        H =ax.hist(X, bins=b,density=True,align=al,alpha=0.5,color=c)\n",
    "        if (Dist=='Unknown'):\n",
    "            textstr = '\\n'.join((\n",
    "                n,\n",
    "                r'$\\mu=%.3f$' % (m, ),\n",
    "                r'max$=%.2f$' % (mx, ),\n",
    "                r'min$=%.2f$' % (mn, ),\n",
    "                r'$\\mathrm{median}=%.2f$' % (me, ),\n",
    "                r'$\\sigma=%.2f$' % (std, ),\n",
    "                r'pearson skewness$=%.2f$' % (sk, ),\n",
    "                r'n$=%.0f$' % (nn, ),\n",
    "                r'std error$=%.3f$' % (std/np.math.sqrt(nn), )))\n",
    "        else:\n",
    "            textstr = '\\n'.join((\n",
    "                n,\n",
    "                r'$\\mu=%.3f$' % (m, ),\n",
    "                r'max$=%.2f$' % (mx, ),\n",
    "                r'min$=%.2f$' % (mn, ),\n",
    "                r'$\\mathrm{median}=%.2f$' % (me, ),\n",
    "                r'$\\sigma=%.2f$' % (std, ),\n",
    "                r'pearson skewness$=%.2f$' % (sk, ),\n",
    "                r'n$=%.0f$' % (nn, ),\n",
    "                r'std error$=%.3f$' % (std/np.math.sqrt(nn), ),\n",
    "                r'pdf utilizada$:$ '+Dist))\n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "        ax.text(p, 0.95, textstr, transform=ax.transAxes, fontsize=11,verticalalignment='top', bbox=props,color=c)\n",
    "        if (Dist!='Unknown'):\n",
    "            if(Dist=='Poisson'):\n",
    "                B=np.arange(mn,mx+1)\n",
    "                ax.plot(B,Poisson_distribution(B,m),color=c,lw=2)\n",
    "            elif(Dist=='Log-norm'):\n",
    "                B=np.linspace(mn,mx,1000)\n",
    "                m_l=np.math.log(m**2/(np.math.sqrt(m**2+std*2)))\n",
    "                std_l=np.math.sqrt(np.math.log(1+((std**2)/(m**2))))\n",
    "                ax.plot(B,Log_normal(B,m_l,std_l),color=c,lw=2)\n",
    "            elif(Dist=='Skellam'):\n",
    "                mu1=(std*2+m)/2\n",
    "                mu2=(std*2-m)/2\n",
    "                B=np.arange(mn,mx+1)\n",
    "                ax.plot(B,skellam.pmf(B,mu1,mu2),color=c,lw=2)\n",
    "            elif(Dist=='Normal'):\n",
    "                B=np.linspace(mn,mx,1000)\n",
    "                ax.plot(B,norm.pdf(B, m, std),color='orange',lw=2)\n",
    "    ax.set_ylabel(y_label,fontsize=16)\n",
    "    ax.set_xlabel(x_label,fontsize=16)\n",
    "    plt.xticks(fontsize=13)\n",
    "    plt.yticks(fontsize=13)\n",
    "    fig.set_size_inches(12,5)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dd44c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_distribution_por_Condicion(DS,Feature,Condition,Cond_Labels,n_bin,Dist,x_label,y_label,al,Text_box_pos=[0.4,0.7]):\n",
    "    '''\n",
    "    Grafica dos histogramas de una feature en función de una condicion. Calcula: media, std, std error, skewness, entre otros.\n",
    "    Si se propone una distribución entre las disponibles (Log-norm, Poisson, Normal, Skellam), \n",
    "    la grafica tomando los valores del histograma.\n",
    "    \n",
    "    Arguments:\n",
    "        DS: DataFrame\n",
    "        Features: Feature a analizar\n",
    "        Condition: Condicion (variable true or False) que separa los datos\n",
    "        Condition_Labels: Que representa True y False\n",
    "        Type: tipo de dato 'historic' or 'match'\n",
    "        n_bin: Lista con numero de bines del histograma\n",
    "        Dist: Lista con Distribución a graficar.\n",
    "        x_label: Lista con nombre del x label de cada subplot\n",
    "        y_label: Lista con nombre del y label de cada subplot\n",
    "        al: alineacion de las barras del histograma 'mid' 'left' or 'right'\n",
    "        text_box_pos: posicion [x,y] del cuadro de texto\n",
    "        xlim: rango en x\n",
    "\n",
    "    '''\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    Local=np.array([])\n",
    "    Visitante=np.array([])\n",
    "    for t in ['home','away']:\n",
    "        C=[t+'_'+Condition+'_'+str(i) for i in range(1,11)]\n",
    "        fil=DS[C].to_numpy()\n",
    "        fil=np.reshape(fil, (np.size(fil),1)).astype('bool')\n",
    "        F=[t+'_'+Feature+'_'+str(i) for i in range(1,11)]\n",
    "        G=DS[F].to_numpy()\n",
    "        G=np.reshape(G, (np.size(G),1))\n",
    "        \n",
    "        Local=np.concatenate((Local,G[fil]))\n",
    "        Visitante=np.concatenate((Visitante,G[~fil]))\n",
    "\n",
    "    for X,n,p,b,c in zip([Local,Visitante],Cond_Labels,Text_box_pos,n_bin,['k','r']):\n",
    "        m=np.nanmean(X)\n",
    "        std=np.nanstd(X)\n",
    "        me=np.nanmedian(X)\n",
    "        sk=3*(m-me)/std\n",
    "        mx=np.nanmax(X)\n",
    "        mn=np.nanmin(X)\n",
    "        nn=np.sum(~np.isnan(X))\n",
    "        H =ax.hist(X, bins=b,density=True,align=al,alpha=0.5,color=c)\n",
    "        if (Dist=='Unknown'):\n",
    "            textstr = '\\n'.join((\n",
    "                n,\n",
    "                r'$\\mu=%.3f$' % (m, ),\n",
    "                r'max$=%.2f$' % (mx, ),\n",
    "                r'min$=%.2f$' % (mn, ),\n",
    "                r'$\\mathrm{median}=%.2f$' % (me, ),\n",
    "                r'$\\sigma=%.2f$' % (std, ),\n",
    "                r'pearson skewness$=%.2f$' % (sk, ),\n",
    "                r'n$=%.0f$' % (nn, ),\n",
    "                r'std error$=%.3f$' % (std/np.math.sqrt(nn), )))\n",
    "        else:\n",
    "            textstr = '\\n'.join((\n",
    "                n,\n",
    "                r'$\\mu=%.3f$' % (m, ),\n",
    "                r'max$=%.2f$' % (mx, ),\n",
    "                r'min$=%.2f$' % (mn, ),\n",
    "                r'$\\mathrm{median}=%.2f$' % (me, ),\n",
    "                r'$\\sigma=%.2f$' % (std, ),\n",
    "                r'pearson skewness$=%.2f$' % (sk, ),\n",
    "                r'n$=%.0f$' % (nn, ),\n",
    "                r'std error$=%.3f$' % (std/np.math.sqrt(nn), ),\n",
    "                r'pdf utilizada$:$ '+Dist))\n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "        ax.text(p, 0.95, textstr, transform=ax.transAxes, fontsize=11,verticalalignment='top', bbox=props,color=c)\n",
    "        if (Dist!='Unknown'):\n",
    "            if(Dist=='Poisson'):\n",
    "                B=np.arange(mn,mx+1)\n",
    "                ax.plot(B,Poisson_distribution(B,m),color=c,lw=2)\n",
    "            elif(Dist=='Log-norm'):\n",
    "                B=np.linspace(mn,mx,1000)\n",
    "                m_l=np.math.log(m**2/(np.math.sqrt(m**2+std*2)))\n",
    "                std_l=np.math.sqrt(np.math.log(1+((std**2)/(m**2))))\n",
    "                ax.plot(B,Log_normal(B,m_l,std_l),color=c,lw=2)\n",
    "            elif(Dist=='Skellam'):\n",
    "                mu1=(std*2+m)/2\n",
    "                mu2=(std*2-m)/2\n",
    "                B=np.arange(mn,mx+1)\n",
    "                ax.plot(B,skellam.pmf(B,mu1,mu2),color=c,lw=2)\n",
    "            elif(Dist=='Normal'):\n",
    "                B=np.linspace(mn,mx,1000)\n",
    "                ax.plot(B,norm.pdf(B, m, std),color='orange',lw=2)\n",
    "    ax.set_ylabel(y_label,fontsize=16)\n",
    "    ax.set_xlabel(x_label,fontsize=16)\n",
    "    plt.xticks(fontsize=13)\n",
    "    plt.yticks(fontsize=13)\n",
    "    fig.set_size_inches(12,5)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d409194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Histograma_condicional_numerica(DF,variable,variable_condicional,tipo_de_condición,condicion_numerica,x_label,legend_pos='best'):\n",
    "    '''\n",
    "    Grafica histograma de la variable, en funcion de la condicion dada.\n",
    "    \n",
    "    Arguments:\n",
    "        DF: DataFrame\n",
    "        variable: Feature para hacer el histograma\n",
    "        variable_condicional: feature que servirá para separar los datos\n",
    "        tipo_de_condición: 'bool' o '><_value'\n",
    "        condicion_numerica: Condición sobre ese feature\n",
    "        X_label: Nombre del feature del histograma\n",
    "\n",
    "    '''\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ind = np.arange(3)\n",
    "    width = 0.2 \n",
    "    if(tipo_de_condición=='><_value'):\n",
    "        ax.bar(ind-width, DF[variable].value_counts(normalize=True) , width, label='General  N='+str(len(DF)), alpha=0.7, color='red')\n",
    "        ax.bar(ind, DF[variable][DF[variable_condicional]>condicion_numerica].value_counts(normalize=True).reindex(DF[variable].value_counts(normalize=True).index) , width, label=variable_condicional+' > '+str(condicion_numerica)+'  N='+str(np.sum(DF[variable_condicional]>condicion_numerica)), alpha=0.7, color='navy')\n",
    "        ax.bar(ind+width, DF[variable][DF[variable_condicional]<-condicion_numerica].value_counts(normalize=True).reindex(DF[variable].value_counts(normalize=True).index), width, label=variable_condicional+' < '+str(-condicion_numerica)+'  N='+str(np.sum(DF[variable_condicional]<-condicion_numerica)), alpha=0.7, color='orange')    \n",
    "    elif(tipo_de_condición=='bool'):\n",
    "        ax.bar(ind-width, DF[variable].value_counts(normalize=True) , width, label='General  N='+str(len(DF)), alpha=0.7, color='red')\n",
    "        ax.bar(ind, DF[variable][DF[variable_condicional]==1].value_counts(normalize=True).reindex(DF[variable].value_counts(normalize=True).index) , width, label=variable_condicional+' = True '+'  N='+str(np.sum(DF[variable_condicional]==1)), alpha=0.7, color='navy')\n",
    "        ax.bar(ind+width, DF[variable][DF[variable_condicional]==0].value_counts(normalize=True).reindex(DF[variable].value_counts(normalize=True).index), width, label=variable_condicional+' = False '+'  N='+str(np.sum(DF[variable_condicional]==0)), alpha=0.7, color='orange')    \n",
    "    ax.set_xlabel(x_label,fontsize=17)\n",
    "    ax.set_ylabel('Distribución de Resultados',fontsize=17)\n",
    "    ax.tick_params(axis='x',labelsize=15,labelrotation=0)\n",
    "    ax.tick_params(axis='y',labelsize=14)\n",
    "    plt.legend(fontsize=12,loc=legend_pos,framealpha=0.9)\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels( (DF[variable].value_counts(normalize=True).index) )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40caf473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Histograma_VAR_categorica(DF,variable,x_label):\n",
    "    '''\n",
    "    Grafica histograma de la variable categorica\n",
    "    \n",
    "    Arguments:\n",
    "        DF: DataFrame\n",
    "        variable: Feature para hacer el histograma\n",
    "        X_label: Nombre del feature del histograma\n",
    "\n",
    "    '''\n",
    "    ax=DF[variable].value_counts(normalize=True).plot(kind='bar',alpha=0.7, color='blue',figsize=(8,5))\n",
    "    ax.set_xlabel(x_label,fontsize=17)\n",
    "    ax.set_ylabel('Distribución de Resultados',fontsize=17)\n",
    "    ax.tick_params(axis='x',labelsize=15,labelrotation=0)\n",
    "    ax.tick_params(axis='y',labelsize=14)\n",
    "    #plt.legend(fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "160f622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Histograma_historic_condition_n_times(DF,variable,variable_condicional,n,x_label,legend_pos='best'):\n",
    "    '''\n",
    "    Grafica histograma de la variable, en funcion de la condicion dada.\n",
    "    \n",
    "    Arguments:\n",
    "        DF: DataFrame\n",
    "        variable: Feature para hacer el histograma\n",
    "        variable_condicional: feature que servirá para separar los datos\n",
    "        n: numero de veces\n",
    "        X_label: Nombre del feature del histograma\n",
    "\n",
    "    '''\n",
    "    \n",
    "    aux=pd.Series(np.zeros(len(DF)),index=DF.index)\n",
    "    for i in range(1,11):\n",
    "        l=variable_condicional+'_{}'.format(i)\n",
    "        aux=aux+DF[l].astype('int')\n",
    "\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ind = np.arange(3)\n",
    "    width = 0.3 \n",
    "    \n",
    "    ax.bar(ind, DF[variable].value_counts(normalize=True) , width, label='General  N='+str(len(DF)), alpha=0.7, color='red')\n",
    "    ax.bar(ind+width, DF[variable][  aux==n  ].value_counts(normalize=True).reindex(DF[variable].value_counts(normalize=True).index) , width, label=variable_condicional+' is True '+str(n)+' veces.   N='+str(np.sum(aux==n)), alpha=0.7, color='navy')\n",
    "    \n",
    "    ax.set_xlabel(x_label,fontsize=17)\n",
    "    ax.set_ylabel('Distribución de Resultados',fontsize=17)\n",
    "    ax.tick_params(axis='x',labelsize=15,labelrotation=0)\n",
    "    ax.tick_params(axis='y',labelsize=14)\n",
    "    plt.legend(fontsize=12,loc=legend_pos,framealpha=0.9)\n",
    "    ax.set_xticks(ind+width/2)\n",
    "    ax.set_xticklabels( (DF[variable].value_counts(normalize=True).index) )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875210f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Histograma_historic_2_condition_n_times(DF,variable,tipo,variable_condicional_1,n1,variable_condicional_2,n2,x_label,legend_pos='best'):\n",
    "    '''\n",
    "    Grafica histograma de la variable, en funcion de la condicion dada.\n",
    "    \n",
    "    Arguments:\n",
    "        DF: DataFrame\n",
    "        variable: Feature para hacer el histograma\n",
    "        tipo: tipo de condición 'both =', 'both >=', '1 >= 2 <='\n",
    "        variable_condicional_1: feature que servirá para separar los datos\n",
    "        n1: numero de veces\n",
    "        variable_condicional_2: feature que servirá para separar los datos\n",
    "        n2: numero de veces\n",
    "        X_label: Nombre del feature del histograma\n",
    "\n",
    "    '''\n",
    "    \n",
    "    aux1=pd.Series(np.zeros(len(DF)),index=DF.index)\n",
    "    for i in range(1,11):\n",
    "        l=variable_condicional_1+'_{}'.format(i)\n",
    "        aux1=aux1+DF[l].astype('int')\n",
    "    \n",
    "    aux2=pd.Series(np.zeros(len(DF)),index=DF.index)\n",
    "    for i in range(1,11):\n",
    "        l=variable_condicional_2+'_{}'.format(i)\n",
    "        aux2=aux2+DF[l].astype('int')\n",
    "\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ind = np.arange(3)\n",
    "    width = 0.3 \n",
    "    \n",
    "    ax.bar(ind, DF[variable].value_counts(normalize=True) , width, label='General  N='+str(len(DF)), alpha=0.7, color='red')\n",
    "    if(tipo=='both ='):\n",
    "        ax.bar(ind+width, DF[variable][  (aux1==n1) &  (aux2==n2)  ].value_counts(normalize=True).reindex(DF[variable].value_counts(normalize=True).index) , width, label=variable_condicional_1+' is True '+str(n1)+' veces\\n'+variable_condicional_2+' is True '+str(n2)+' veces\\n'+   'N='+str(np.sum((aux1==n1)&(aux2==n2))), alpha=0.7, color='navy')\n",
    "    elif(tipo=='both >='):    \n",
    "        ax.bar(ind+width, DF[variable][  (aux1>=n1) &  (aux2>=n2)  ].value_counts(normalize=True).reindex(DF[variable].value_counts(normalize=True).index) , width, label=variable_condicional_1+' is True '+str(n1)+' veces al menos\\n'+variable_condicional_2+' is True '+str(n2)+' veces al menos\\n'+   'N='+str(np.sum((aux1>=n1)&(aux2>=n2))), alpha=0.7, color='navy')\n",
    "    elif(tipo=='1 >= 2 <='):    \n",
    "        ax.bar(ind+width, DF[variable][  (aux1>=n1) &  (aux2<=n2)  ].value_counts(normalize=True).reindex(DF[variable].value_counts(normalize=True).index) , width, label=variable_condicional_1+' is True '+str(n1)+' veces al menos\\n'+variable_condicional_2+' is True '+str(n2)+' veces al menos\\n'+   'N='+str(np.sum((aux1>=n1)&(aux2<=n2))), alpha=0.7, color='navy')\n",
    "    \n",
    "    \n",
    "    ax.set_xlabel(x_label,fontsize=17)\n",
    "    ax.set_ylabel('Distribución de Resultados',fontsize=17)\n",
    "    ax.tick_params(axis='x',labelsize=15,labelrotation=0)\n",
    "    ax.tick_params(axis='y',labelsize=14)\n",
    "    plt.legend(fontsize=12,loc=legend_pos,framealpha=0.9)\n",
    "    ax.set_xticks(ind+width/2)\n",
    "    ax.set_xticklabels( (DF[variable].value_counts(normalize=True).index) )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4af07d",
   "metadata": {},
   "source": [
    "### Matrices de correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "762ea6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04d418bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Matrices_de_correlacion_All_Features_a_la_vez(DS):\n",
    "    '''\n",
    "    Genera matrices de correlacion para todas las features del dataset.\n",
    "    Las referentes al partido a modelar, las agrupa en un solo subplot.\n",
    "    Para las históricas, se genera un subplot para cada una.\n",
    "    \n",
    "    Arguments:\n",
    "        DS: DataFrame\n",
    "        \n",
    "    '''\n",
    "    n_DS= pd.get_dummies(DS, columns=['target'])\n",
    "    Lista=list(n_DS.columns)[:-3]+['Victoria visitante','Empate','Victoria local']\n",
    "    rename_columns(n_DS,Lista)\n",
    " \n",
    "    Match_day_features=[]\n",
    "    for c in n_DS.columns:\n",
    "        if ( (c!='id') and not(bool(re.search(r'\\d', c)))):\n",
    "            Match_day_features.append(c)\n",
    "    corrMatrix_matchday =n_DS[Match_day_features].corr()\n",
    "    \n",
    "    M={}\n",
    "    Features=['goal_diff','rating_diff','coach_continuity','team_history_is_play_home','team_history_is_cup']\n",
    "    for f in Features:\n",
    "        Col=[]\n",
    "        for t in ['home','away']:\n",
    "            for i in range(1,11):\n",
    "                c=t+'_'+f+'_{}'.format(i)\n",
    "                Col.append(c)\n",
    "        Col=Col+['Victoria visitante','Empate','Victoria local']\n",
    "        M[f]=n_DS[Col].corr()\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(3, 2, figsize=(25,30))\n",
    "    axes=np.reshape(axes,(6,))\n",
    "    \n",
    "    axes[0].set_title(r'$sign(M)\\,\\sqrt{abs(M)}$'+', siendo M la matriz de correlacion para las variables del partido\\n', fontsize=14)\n",
    "    sns.heatmap(np.sign(corrMatrix_matchday)*np.sqrt(np.abs(corrMatrix_matchday)), annot=True,ax=axes[0], cmap=\"vlag\")\n",
    "    \n",
    "    for a,f in zip(axes[1:],Features):\n",
    "        a.set_title(r'$sign(M)\\,\\sqrt{abs(M)}$'+', siendo M la matriz de correlacion para las variables \"{}\"\\n'.format(f.replace('_', ' ')), fontsize=14)\n",
    "        sns.heatmap(np.sign(M[f])*np.sqrt(np.abs(M[f])), annot=True,ax=a , cmap=\"vlag\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af5e5942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Matrices_de_correlacion_All_Features(DS,tipo,historic_feature=None):\n",
    "    '''\n",
    "    Genera una matriz de correlacion para las features seleccionadas. \n",
    "    \n",
    "    Arguments:\n",
    "        DS: DataFrame\n",
    "        tipo: 'Match_day_Features' para las del partido a modelar, o 'Historicas' para una feature historica\n",
    "        historic_feature: nombre de la feature cuando es de categoria 'Historicas'\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    n_DS= pd.get_dummies(DS, columns=['target'])\n",
    "    Lista=list(n_DS.columns)[:-3]+['Victoria visitante','Empate','Victoria local']\n",
    "    rename_columns(n_DS,Lista)\n",
    "    \n",
    "    if(tipo=='Match_day_Features'):\n",
    "        Col=[]\n",
    "        for c in n_DS.columns:\n",
    "            if ( (c!='id') and not(bool(re.search(r'\\d', c)))):\n",
    "                Col.append(c)\n",
    "    elif(tipo=='Historicas'):\n",
    "        if(historic_feature==None):\n",
    "            print('Historic feature needs to be specify as an additional argument')\n",
    "            return\n",
    "        f=historic_feature\n",
    "        Col=[]\n",
    "        for t in ['home','away']:\n",
    "            for i in range(1,11):\n",
    "                c=t+'_'+f+'_{}'.format(i)\n",
    "                Col.append(c)\n",
    "        Col=Col+['Victoria visitante','Empate','Victoria local']\n",
    "        \n",
    "    M=n_DS[Col].corr()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 1, figsize=(18,8))\n",
    "\n",
    "    if(tipo=='Match_day_Features'):\n",
    "        label='del partido'\n",
    "    elif(tipo=='Historicas'):\n",
    "        label='historicas de '+historic_feature.replace('_', ' ')\n",
    "    \n",
    "    axes.set_title(r'$sign(M)\\,\\sqrt{abs(M)}$'+', siendo M la matriz de correlacion para las variables \"{}\"\\n'.format(label), fontsize=18)\n",
    "    sns.heatmap(np.sign(M)*np.sqrt(np.abs(M)), annot=True,ax=axes, cmap='vlag' )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acf3a45",
   "metadata": {},
   "source": [
    "### Otros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "617ef311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Best_rating_teams(DS,N,league=[-1,'None']):\n",
    "    '''\n",
    "    Genera una tabla (DataFrame) con los mejores N equipos de una liga, o en su defecto del dataset.\n",
    "    \n",
    "    Arguments:\n",
    "        DS: DataFrame\n",
    "        N: numero de equipos en la lista\n",
    "        league: [id,nombre]\n",
    "\n",
    "    '''\n",
    "    f='team_history_rating'\n",
    "    c_h=[t+'_'+f+'_'+str(i) for t in ['home'] for i in range(1,11)]\n",
    "    C_home=['home_team_name']+c_h\n",
    "    \n",
    "    c_a=[t+'_'+f+'_'+str(i) for t in ['away'] for i in range(1,11)]\n",
    "    C_away=['away_team_name']+c_a\n",
    "    \n",
    "    idd=league[0]\n",
    "    if(idd==-1):\n",
    "        print('Todas las Ligas del Dataset\\n')\n",
    "        DS_2=DS\n",
    "    elif(idd in DS.league_id.unique()):\n",
    "        print('Liga: '+league[1])\n",
    "        DS_2=DS[DS.league_id==idd]\n",
    "        \n",
    "    X_home=DS_2[C_home]\n",
    "    X_home['Rank']=X_home[c_h].mean(axis=1)\n",
    "    X_home=X_home.drop(columns=c_h)\n",
    "\n",
    "    X_away=DS_2[C_away]\n",
    "    X_away['Rank']=X_away[c_a].mean(axis=1)\n",
    "    X_away=X_away.drop(columns=c_a)\n",
    "    \n",
    "    rename_columns(X_home,['Equipo','Rating'])\n",
    "    rename_columns(X_away,['Equipo','Rating'])\n",
    "    \n",
    "    X = pd.concat([X_home,X_away])\n",
    "\n",
    "    X=X.groupby('Equipo').mean()\n",
    "    \n",
    "    X=X.sort_values('Rating',ascending=False)\n",
    "    \n",
    "    display(X.head(N))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe13086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Correlacion_X_vs_Y_his(DS,X_label,Y_label,Plot_labels,alpha=1,text_x_pos=0.7):\n",
    "    '''\n",
    "    Grafica el scatter plot de dos features y calcula su correlación.\n",
    "    \n",
    "    Arguments:\n",
    "        DS: DataFrame\n",
    "        X_label: Feature X\n",
    "        Y_label: Feature Y\n",
    "        Plot_labels= nombre de los labels [x,y]\n",
    "        alpha: nivel de trasparencia de los puntos\n",
    "        x_pos: posicion x del cuadro de texto donde aparece el valor de correlacion\n",
    "\n",
    "    '''\n",
    "    X_c=[]\n",
    "    for xl in X_label:\n",
    "        X_c=X_c+[t+'_'+xl+'_'+str(i) for t in ['home','away'] for i in range(1,11)]\n",
    "    X=DS[X_c].to_numpy()\n",
    "    X=np.reshape(X, (np.size(X),))\n",
    "    \n",
    "    Y_c=[]\n",
    "    for yl in Y_label:\n",
    "        Y_c=Y_c+[t+'_'+yl+'_'+str(i) for t in ['home','away'] for i in range(1,11)]\n",
    "    Y=DS[Y_c].to_numpy()\n",
    "    Y=np.reshape(Y, (np.size(Y),))\n",
    "    \n",
    "    corr=np.ma.corrcoef(np.ma.masked_invalid(X), np.ma.masked_invalid(Y))\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlabel(Plot_labels[0],fontsize=17)\n",
    "    ax.set_ylabel(Plot_labels[1],fontsize=17)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=17)\n",
    "    ax.scatter(X,Y,alpha=alpha)\n",
    "    textstr = r'$Correlation\\,\\,Value=%.3f$' % (corr[0,1], )\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    ax.text(text_x_pos, 0.95, textstr, transform=ax.transAxes, fontsize=16,verticalalignment='top', bbox=props,color='k')\n",
    "    fig.set_size_inches(20,5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a1c7b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Outcome_para_copa_y_liga(DS):\n",
    "    '''\n",
    "    Realiza un grafico de barras con los porcentages de Victoria, Empate y Derrota para partidos de: Copa, Liga y General.\n",
    "    \n",
    "    Arguments:\n",
    "        DS: DataFrame\n",
    "        \n",
    "    '''\n",
    "    Total=DS.target.value_counts()/len(DS.target)\n",
    "    Copa=DS[DS.is_cup==True].target.value_counts()/len(DS[DS.is_cup==True])\n",
    "    Liga=DS[DS.is_cup==False].target.value_counts()/len(DS[DS.is_cup==False])\n",
    "    \n",
    "    X=np.arange(3)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_ylabel('Distribución de Resultados',fontsize=17)\n",
    "    ax.set_xlabel('Resultado',fontsize=17)\n",
    "    ax.bar(X-0.11,Total.values,width=0.1,label='General')\n",
    "    ax.bar(X,Liga.values,width=0.1,label='Liga')\n",
    "    ax.bar(X+0.11,Copa.values,width=0.1,label='Copa')\n",
    "    \n",
    "    xt=[item.get_text() for item in ax.get_xticklabels()]\n",
    "    xt[1]=Total.index[0]\n",
    "    xt[3]=Total.index[1]\n",
    "    xt[5]=Total.index[2] \n",
    "    ax.set_xticklabels(xt)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=17)\n",
    "    \n",
    "    plt.legend()\n",
    "    fig.set_size_inches(10,5)\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0991afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Match_dates_histograms(DS):\n",
    "    '''\n",
    "    Genera un histograma con las fechas de los partidos, separando partidos a modelar de los hitoricos del input.\n",
    "    \n",
    "    Arguments:\n",
    "        DS: DataFrame\n",
    "        \n",
    "    '''\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    Feature='team_history_match_date'\n",
    "    C=[t+'_'+Feature+'_'+str(i) for t in ['home','away'] for i in range(1,11)]\n",
    "    X=DS[C].to_numpy()\n",
    "    X=np.reshape(X, (np.size(X),1))\n",
    "    \n",
    "    H=pd.DataFrame(X).dropna()\n",
    "    rename_columns(H,['Date'])\n",
    "    H.Date=H.Date.astype(\"datetime64\")\n",
    "    H['Year']= H.Date.dt.year\n",
    "    H['Month']=H.Date.dt.month\n",
    "    Values_Historic=H.groupby(['Year','Month']).count()\n",
    "    Values_Historic=100*Values_Historic/Values_Historic.Date.sum()\n",
    "    \n",
    "    X1=np.arange(len(Values_Historic))\n",
    "    Y1=Values_Historic.values[:,0]\n",
    "    ax.bar(X1,Y1,color='black',alpha=0.3,label='Partidos Historial')\n",
    "    \n",
    "    \n",
    "    T = DS.match_date.astype(\"datetime64\")\n",
    "    T=pd.DataFrame(T)\n",
    "    rename_columns(T,['Date'])\n",
    "    T['Year']=T.Date.dt.year\n",
    "    T['Month']=T.Date.dt.month\n",
    "    Values_Match_day=T.groupby(['Year','Month']).count()\n",
    "    Values_Match_day=100*Values_Match_day/Values_Match_day.Date.sum()\n",
    "    \n",
    "    \n",
    "    X2=np.arange(len(Values_Match_day))+11\n",
    "    Y2=Values_Match_day.values[:,0]\n",
    "    ax.bar(X2,Y2,color='red',alpha=0.3,label='Partidos a Modelar')\n",
    "    \n",
    "    \n",
    "    ax.set_ylabel('Porcentage de Partidos (%)',fontsize=17)\n",
    "    ax.set_xlabel('Fecha',fontsize=17)\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "    ax.set_xticks(np.arange(min(X1), max(X2)+1, 1.0))\n",
    "    \n",
    "    xt=[item.get_text() for item in ax.get_xticklabels()]\n",
    "    xt=list(Values_Historic.index)\n",
    "    xt.append((Values_Match_day.index)[-1])\n",
    "    ax.set_xticklabels(xt,rotation=90)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    fig.set_size_inches(10,5)\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7316cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Trainer_effect_on_the_outcome(DS,dias_ventana):\n",
    "    '''\n",
    "    Analiza el efecto de cambios de entrenadores en termino de porcentage de victorias, derrotas y empates, \n",
    "    y el tiempo transcurrido desde dicho evento. Realiza un grafico y una tabla donde se muestran los resultados.\n",
    "    \n",
    "    Arguments:\n",
    "        DS: DataFrame\n",
    "        dias_ventana: número de dias a analizar alrrededor del cambio de entrenador\n",
    "        \n",
    "    '''\n",
    "    K=list(np.arange(-dias_ventana,dias_ventana+1))#[-3,-2,-1,0,1,2,3]\n",
    "    Victorias=[]\n",
    "    Derrotas=[]\n",
    "    Empates=[]\n",
    "    Muestras=[]\n",
    "    Local=[]\n",
    "    for k in K:\n",
    "        C=np.array([])\n",
    "        D=np.array([])\n",
    "        V=np.array([])\n",
    "        L=np.array([])\n",
    "        for t in ['home','away']:\n",
    "            for i in range(max(1,1-k),min(10,10-k)):\n",
    "                c=t+'_coach_continuity_{}'.format(i)\n",
    "                d=t+'_outcome_V_{}'.format(i+k)\n",
    "                v=t+'_outcome_D_{}'.format(i+k)\n",
    "                l=t+'_team_history_is_play_home_{}'.format(i)\n",
    "                C=np.concatenate((C,DS[c].to_numpy()))\n",
    "                D=np.concatenate((D,DS[d].to_numpy()))\n",
    "                V=np.concatenate((V,DS[v].to_numpy()))\n",
    "                L=np.concatenate((L,DS[l].to_numpy()))\n",
    "        n=len(C[C==0])\n",
    "        p_v=np.sum(V[C==0])/n\n",
    "        p_d=np.sum(D[C==0])/n\n",
    "        p_e=1-p_d-p_v\n",
    "        p_l=np.sum(L[C==0])/n\n",
    "        Victorias.append(p_v)\n",
    "        Empates.append(p_e)\n",
    "        Derrotas.append(p_d)\n",
    "        Muestras.append(n)\n",
    "        Local.append(p_l)\n",
    "        if(k==0):\n",
    "            n=len(C)\n",
    "            p_v=np.sum(V)/n\n",
    "            p_d=np.sum(D)/n\n",
    "            p_e=1-p_d-p_v\n",
    "            p_l=np.sum(L)/n\n",
    "            Victorias=[p_v]+Victorias\n",
    "            Empates=[p_e]+Empates\n",
    "            Derrotas=[p_d]+Derrotas\n",
    "            Muestras=[n]+Muestras\n",
    "            Local=[p_l]+Local\n",
    "    LABEL=['General']\n",
    "    for k in K:\n",
    "        if(k<0):\n",
    "            LABEL=LABEL+['{} partidos antes de un cambio de entrenador'.format(abs(k))]\n",
    "        elif(k>0):\n",
    "            LABEL=LABEL+['{} partidos después de un cambio de entrenador'.format(abs(k))]\n",
    "        elif(k==0):\n",
    "            LABEL=LABEL+['En el partido de un cambio de entrenador'.format(abs(k))]\n",
    "    df={'Condición':LABEL,\n",
    "        'Muestras': Muestras,\n",
    "        '% Local': np.round(100*np.array(Local),2),\n",
    "        '% Victorias':np.round(100*np.array(Victorias),2),\n",
    "        '% Empates:':np.round(100*np.array(Empates),2),\n",
    "        '% Derrotas':np.round(100*np.array(Derrotas),2)}\n",
    "    df=pd.DataFrame(df)\n",
    "    display(df)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlabel('Partidos hasta cambio de Entrenador',fontsize=16)\n",
    "    ax.set_ylabel('Distribución de Resultados',fontsize=16)\n",
    "    ax.plot(K,Victorias[1:],'-o',label='% Victorias')\n",
    "    ax.plot(K,Empates[1:],'-o',label='% Empates')\n",
    "    ax.plot(K,Derrotas[1:],'-o',label='% Derrotas')\n",
    "    ax.axvline(0,ls='--',lw=2,c='darkgrey')\n",
    "    ax.axhline(Victorias[0],ls='--',lw=1,c='b')\n",
    "    ax.axhline(Empates[0],ls='--',lw=1,c='orange')\n",
    "    ax.axhline(Derrotas[0],ls='--',lw=1,c='green')\n",
    "    textstr = 'Las líneas punteadas indican\\nlos valores en el data set completo'\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    ax.text(0.01, 0.98, textstr, transform=ax.transAxes, fontsize=13,verticalalignment='top', bbox=props,color='k')\n",
    "    plt.xticks(fontsize=13)\n",
    "    plt.yticks(fontsize=13)\n",
    "    plt.legend(loc=(0.01, 0.3), prop={'size': 14})\n",
    "    fig.set_size_inches(12,5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5b3d7d",
   "metadata": {},
   "source": [
    "## TRANSFORMACIÓN DEL DATASET PARA LOS MODELOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ba073c",
   "metadata": {},
   "source": [
    "### Balance de targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57e3f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classes_counts(DS):\n",
    "    '''\n",
    "    Imprime por pantalla las clases en el Dataframe de target y su ocurrencia/frecuencia.\n",
    "    \n",
    "    Arguments:\n",
    "        DS: DataFrame\n",
    "        \n",
    "    '''\n",
    "    v,q=np.unique(DS.target,return_counts=True)\n",
    "    n=np.sum(q)\n",
    "    ddict=dict(zip(v,q))\n",
    "    print('CLASES\\n')\n",
    "    for k in ddict.keys():\n",
    "        print(k,': ',ddict[k],' ',round(100*ddict[k]/n,2),'%')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f84b5c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_balancing_Victorias_y_Derrotas(DS):\n",
    "    '''\n",
    "    Balancea las clases \"away\" y \"home\" a través de intercambiar visitantes y locales. Ahora pasan a llamarse Equipo 1 y\n",
    "    Equipo 2, y la información de localía queda condensada en la variable \"EqA_Local\". También realiza un mezclado de las\n",
    "    muestras.\n",
    "    \n",
    "    Devuelve el Dataframe resultante.\n",
    "    \n",
    "    Arguments:\n",
    "        DS: DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        DS_2: Dataframe resultante\n",
    "    '''\n",
    "    #This function swaps 0.5 of the home and away, and oversamples draws \n",
    "    ###################################################################\n",
    "    \n",
    "    DS_2=DS.copy(deep=True)\n",
    "    DS_2['EqA_Local']=np.ones(len(DS_2)).astype('int')\n",
    "    DS_2['swap']=np.random.randint(0,2,len(DS_2))\n",
    "    \n",
    "    t='target'\n",
    "    DS_2[t+'_2']=(DS_2[t]=='away').astype('int')*(-1)+(DS_2[t]=='home').astype('int')\n",
    "    \n",
    "    c='swap'\n",
    "    \n",
    "    #times -1\n",
    "    Features=['Rating_diff','diff_num_partidos_tres_semanas','diff_num_partidos_diez_dias','diff_num_partidos_cuatro_dias','target_2']\n",
    "    for f in Features:\n",
    "        DS_2[f]=DS_2[f]*(DS_2[c]==0).astype('int')+DS_2[f]*(DS_2[c]==1).astype('int')*(-1)\n",
    "    \n",
    "    #1 to 0 and 0 to 1\n",
    "    Features=['EqA_Local']\n",
    "    for f in Features:\n",
    "        DS_2[f]=DS_2[f]*(DS_2[c]==0).astype('int')+np.abs(DS_2[f]-1)*(DS_2[c]==1).astype('int')\n",
    "    \n",
    "    #intercambio away/home\n",
    "    Features=['coach_continuity','partidos_tres_semanas','partidos_diez_dias','partidos_cuatro_dias']\n",
    "    for f in Features:\n",
    "        h_cc='home_'+f\n",
    "        a_cc='away_'+f\n",
    "        aux_h='aux'\n",
    "    \n",
    "        DS_2[aux_h]=DS_2[h_cc]\n",
    "            \n",
    "        DS_2[h_cc]=DS_2[h_cc]*(DS_2[c]==0).astype('int')+(DS_2[c]==1).astype('int')*DS_2[a_cc]\n",
    "\n",
    "        DS_2[a_cc]=DS_2[a_cc]*(DS_2[c]==0).astype('int')+(DS_2[c]==1).astype('int')*DS_2[aux_h]\n",
    "\n",
    "        DS_2=DS_2.drop(columns=[aux_h]) \n",
    "    \n",
    "    #intercambio away/home\n",
    "    historic_feature=['goal_diff','rating_diff','result_ponderado','coach_continuity','team_history_is_play_home','team_history_is_cup','outcome_V','outcome_D','relevance']\n",
    "    h='home'\n",
    "    a='away'\n",
    "    for f in historic_feature:\n",
    "        for i in range(1,11):\n",
    "            l='_'+f+'_{}'.format(i)\n",
    "            aux_h=h+l+'_aux'\n",
    "            \n",
    "            DS_2[aux_h]=DS_2[h+l]\n",
    "            \n",
    "            DS_2[h+l]=DS_2[h+l]*(DS_2[c]==0).astype('int')+(DS_2[c]==1).astype('int')*DS_2[a+l]\n",
    "            \n",
    "            DS_2[a+l]=DS_2[a+l]*(DS_2[c]==0).astype('int')+(DS_2[c]==1).astype('int')*DS_2[aux_h]\n",
    "            \n",
    "            DS_2=DS_2.drop(columns=[aux_h]) \n",
    "            \n",
    "    #mapear targets\n",
    "    t='target'\n",
    "    map_dic={-1:'EqA_Derrota',0:'EqA_Empate',1:'EqA_Victoria'}\n",
    "    DS_2[t]=DS_2[t+'_2'].map(map_dic)\n",
    "    \n",
    "    #cambiar nombres a eq1 y eq2\n",
    "    Names={}\n",
    "    for c in DS_2.columns:\n",
    "        c2=c.replace('home','Equipo_A')\n",
    "        c3=c2.replace('away','Equipo_B')\n",
    "        if(  'team_history_is_play' in c3  ):\n",
    "            c3=c3.replace('team_history_is_play_Equipo_A','play_home')\n",
    "        elif(  'team_history_is_cup' in c3  ):\n",
    "            c3=c3.replace('team_history_is_cup','is_cup')\n",
    "        Names[c]=c3\n",
    "    DS_2=DS_2.rename(columns=Names)\n",
    "    \n",
    "    #Shufle and Reset index\n",
    "    DS_2 = DS_2.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    #Drop columnas\n",
    "    DS_2=DS_2.drop(columns=['swap','target_2']) \n",
    "    \n",
    "    #print\n",
    "    display(DS_2)\n",
    "    \n",
    "    return DS_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e532a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balance_de_empates_por_under_and_over_sampling(DS):\n",
    "    '''\n",
    "    Balancea las clases \"Empate\" con Derrota y Victoria a través de realizar un oversampling de los empates y un \n",
    "    undersampling de las derrotas y victorias. Todas las clases son afectadas porcentualmente de la misma manera. \n",
    "    \n",
    "    Devuelve el Dataframe resultante.\n",
    "    \n",
    "    Arguments:\n",
    "        DS: DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        DS_2: Dataframe\n",
    "    '''\n",
    "    DS_2=DS.copy(deep=True)\n",
    "    # oversampling de Empate\n",
    "    v,q=np.unique(DS_2.target,return_counts=True)\n",
    "    ddict=dict(zip(v,q))\n",
    "    ratio=((ddict['EqA_Derrota']+ddict['EqA_Victoria'])/2)/ddict['EqA_Empate']\n",
    "    x=(ratio-1)/(ratio+1)#proporcion a aumentar(reducir) la clase empates (victoria/derrota) para alcanzar un balance\n",
    "    print('Ratio Victorias(Derrotas)/Empates= ',round(ratio,2))\n",
    "    print('Proporcion a cambiar clases= ',round(100*x,2),'%')\n",
    "    \n",
    "    #Random selection\n",
    "    DS_2['resamp_idx']=(np.random.rand(len(DS_2))>(1-x)).astype('int')\n",
    " \n",
    "    #Oversampling\n",
    "    DS_2=DS_2.loc[DS_2.index.repeat(1 + DS_2.resamp_idx*(DS_2.target=='EqA_Empate').astype('int'))]\n",
    "    \n",
    "    #Undersampling\n",
    "    DS_2 = DS_2[(DS_2.target=='EqA_Empate') | (DS_2.resamp_idx==0)]\n",
    "    \n",
    "    #droping of auciliar feature\n",
    "    DS_2=DS_2.drop(columns=['resamp_idx'])\n",
    "    \n",
    "    return DS_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb881d27",
   "metadata": {},
   "source": [
    "### Separación del *Dataset* en *train* y *test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3714fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b78d282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_of_categories(y_train,y_test):\n",
    "    '''\n",
    "    Genera e imprime por pantalla un report del output para el trainset y el testset, mostrando las ocurrencias y\n",
    "    distribución de clases\n",
    "    \n",
    "    Arguments:\n",
    "        y_train: target train\n",
    "        y_test: target test\n",
    "    '''\n",
    "    Tabla={}\n",
    "    Tabla['train']=y_train.sum()\n",
    "    Tabla['train %']=y_train.sum()/len(y_train)\n",
    "    Tabla['test']=y_test.sum()\n",
    "    Tabla['test %']=y_test.sum()/len(y_test)\n",
    "    Tabla=pd.DataFrame(Tabla)\n",
    "    display(Tabla)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cdbb4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Training_Test_separation(DF,print_report=True,test_size=0.2):\n",
    "    '''\n",
    "    Separa el dataframe en test y train\n",
    "    \n",
    "    Arguments:\n",
    "        DS: DataFrame\n",
    "        print_report: si es \"True\" imprime un reporte de ambos datasets\n",
    "        size: tamaño del testset\n",
    "        \n",
    "    Returns:\n",
    "        TRAIN: train dataset\n",
    "        TEST: test dataset\n",
    "    '''\n",
    "    X=DF.drop(columns=['target'])\n",
    "    y=DF.target\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "    sss.get_n_splits(X, y)\n",
    "    \n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "        TRAIN=DF.iloc[train_index]\n",
    "        TEST=DF.iloc[test_index]\n",
    "        if(print_report):\n",
    "            dist_of_categories(pd.get_dummies(y[train_index]),pd.get_dummies(y[test_index]))\n",
    "    return TRAIN,TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21500bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Split_input_and_OHE_output(DS_train,DS_test,print_report=True):\n",
    "    '''\n",
    "    Separa los train y test datasets en input y output, realizando un one-hot encoding en el segundo\n",
    "    \n",
    "    Arguments:\n",
    "        DS_train: Dataset train\n",
    "        DS_test: Dataset test\n",
    "        print_report: si es \"True\" imprime un reporte sobre los outputs\n",
    "        \n",
    "    Returns:\n",
    "        X_train: train dataset input\n",
    "        y_train: target train\n",
    "        X_test: test dataset input\n",
    "        y_test: target test\n",
    "    '''\n",
    "    \n",
    "    X_train=DS_train.drop(columns=['target'])\n",
    "    y_train=DS_train.target\n",
    "    \n",
    "    X_test=DS_test.drop(columns=['target'])\n",
    "    y_test=DS_test.target\n",
    "    \n",
    "    y_train=pd.get_dummies(y_train)\n",
    "    y_test=pd.get_dummies(y_test)\n",
    "    \n",
    "    if(print_report):\n",
    "        dist_of_categories(y_train,y_test)\n",
    "        \n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9226222",
   "metadata": {},
   "source": [
    "### Transformación y estandarización para cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13ceee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepara_DF_para_Random_Forest(DF_train,DF_test,Features_His,Features_Match,Features_His_to_std,Features_Match_to_std):\n",
    "    '''\n",
    "    Prepara y estandariza un Dataframe  para modelarlo por Random Forest\n",
    "    \n",
    "    Arguments:\n",
    "        DF: DataFrame train\n",
    "        DF: DataFrame test\n",
    "        Features_His: Features partidos anteriores\n",
    "        Features_Match: Features partido a modelar\n",
    "        Features_His_to_std: Features historicas a estandarizar\n",
    "        Features_Match_to_std: Features del partido a estandarizar:\n",
    "        \n",
    "    Returns:\n",
    "        X : train input \n",
    "        y:: train input \n",
    "        X : test input \n",
    "        y:: test input \n",
    "    '''\n",
    "    y=DF_train.target\n",
    "    X=DF_train.drop(columns=['target','id'])\n",
    "    \n",
    "    y_t=DF_test.target\n",
    "    X_t=DF_test.drop(columns=['target','id'])\n",
    "    \n",
    "    C=[]\n",
    "    for f in Features_His:\n",
    "        for i in range(1,11):\n",
    "            if((i!=10 )|(f!='coach_continuity')):\n",
    "                C=C+[t+'_'+f+'_'+str(i) for t in ['Equipo_A','Equipo_B']]\n",
    "    C=C+Features_Match\n",
    "    \n",
    "    X=X[C]\n",
    "    X_t=X_t[C]\n",
    "    \n",
    "    Std_FMP=Standarizador_normal()\n",
    "    \n",
    "    Cs=[]\n",
    "    for f in Features_His_to_std:\n",
    "            Cs=Cs+[t+'_'+f+'_'+str(i) for t in ['Equipo_A','Equipo_B'] for i in range(1,11)]\n",
    "    Cs=Cs+Features_Match_to_std\n",
    "    for c in C:\n",
    "        Std_FMP.fit(X,c)\n",
    "        Std_FMP.transform(X,c)\n",
    "        Std_FMP.transform(X_t,c)\n",
    "    \n",
    "    print('train')\n",
    "    check_NaNs(X)\n",
    "    print('test')\n",
    "    check_NaNs(X_t)\n",
    "    return X,y,X_t,y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45f37dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_for_NN(X_train,X_test,H_Features,N_Features,oldest_match=10,standarize=True):\n",
    "    '''\n",
    "    Da forma a un dataframe para servir de input de una red neuronal densa. Permite estandarizar las variables. \n",
    "    Para las variables históricas, la standarización se hace sobre las 10 columnas de los 10 partidos todo al mismo tiempo.\n",
    "    \n",
    "    Arguments:\n",
    "        X_train: train input\n",
    "        X_test: test input\n",
    "        H_Features: Features historicas a considerar\n",
    "        N_Features: Features del partido a considerar\n",
    "        oldest_match: Numero de partidos historicos a considerar\n",
    "        standarize: estandarizacion\n",
    "\n",
    "        \n",
    "    Returns:\n",
    "        X_train_out : train input \n",
    "        X_test_out: test input \n",
    "    '''\n",
    "    C=[]\n",
    "    for f in N_Features:\n",
    "        C=C+[f]\n",
    "    for f in H_Features:\n",
    "        C=C+[t+'_'+f+'_'+str(i) for t in ['Equipo_A','Equipo_B'] for i in range(1,oldest_match+1)]\n",
    "    X_train_out=X_train[C]\n",
    "    X_test_out=X_test[C]\n",
    "    if (standarize==True):\n",
    "        S=Standarizador()\n",
    "        for f in H_Features:\n",
    "            C=[t+'_'+f+'_'+str(i) for t in ['Equipo_A','Equipo_B'] for i in range(1,oldest_match+1)]\n",
    "            S.fit(X_train_out[C],f)\n",
    "            X_train_out[C]=S.transform(X_train_out[C],f)\n",
    "            X_test_out[C]=S.transform(X_test_out[C],f)\n",
    "        for f in N_Features:\n",
    "            S.fit(X_train_out[f],f)\n",
    "            X_train_out[f]=S.transform(X_train_out[f],f)\n",
    "            X_test_out[f]=S.transform(X_test_out[f],f)\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train_out=X_train_out.to_numpy()\n",
    "    X_test_out=X_test_out.to_numpy()\n",
    "    \n",
    "    print('Train shape:', np.shape(X_train_out))\n",
    "    print('Test shape:', np.shape(X_test_out))\n",
    "    \n",
    "    return X_train_out,X_test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cec5c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_for_RNN(X_train,X_test,Features,Equipos,oldest_match=10,standarize=True):\n",
    "    '''\n",
    "    Da forma a un dataframe para servir de input de una red neuronal recurrente. Permite estandarizar las variables. \n",
    "    La standarización se hace sobre todas la columnas de los partidos todo al mismo tiempo.\n",
    "    \n",
    "    Arguments:\n",
    "        X_train: train input\n",
    "        X_test: test input\n",
    "        Features: Features historicas a considerar\n",
    "        Equipos: Equipos a considerar (A, B, o AyB), lista\n",
    "        oldest_match: Numero de partidos historicos a considerar\n",
    "        standarize: estandarizacion\n",
    "\n",
    "        \n",
    "    Returns:\n",
    "        M : train input \n",
    "        M_t: test input \n",
    "    '''\n",
    "    X={}\n",
    "    X_t={}\n",
    "    for f in Features:\n",
    "        C=[t+'_'+f+'_'+str(i) for t in Equipos for i in range(1,oldest_match+1)]\n",
    "        X[f]=X_train[C]\n",
    "        X_t[f]=X_test[C]\n",
    "\n",
    "    if (standarize==True):\n",
    "        S=Standarizador()\n",
    "        for f in Features:\n",
    "            S.fit(X[f],f)\n",
    "            X[f]=S.transform(X[f],f)\n",
    "            X_t[f]=S.transform(X_t[f],f)\n",
    "    M=[]\n",
    "    M_t=[]\n",
    "    for i in range(oldest_match,0,-1):\n",
    "        L=[]\n",
    "        L_t=[]\n",
    "        for t in Equipos:\n",
    "            for f in Features:\n",
    "                c=t+'_'+f+'_'+str(i)\n",
    "                L.append(X[f][c])\n",
    "                L_t.append(X_t[f][c])\n",
    "        M.append(L)\n",
    "        M_t.append(L_t)\n",
    "        \n",
    "    M=np.array(M)\n",
    "    M_t=np.array(M_t)\n",
    "    \n",
    "    M=M.transpose((2,0,1))\n",
    "    M_t=M_t.transpose((2,0,1))\n",
    "    \n",
    "    print('Train shape:', np.shape(M))\n",
    "    print('Test shape:', np.shape(M_t))\n",
    "    \n",
    "    return M, M_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdb4053",
   "metadata": {},
   "source": [
    "### Principal component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a83c6bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_analisis(X,X_t,Action='Fit',umbral=100):\n",
    "    '''\n",
    "    Hace un Principal component analysis (PCA) del dataframe. Y reduce la dimensionalidad dependiendo el umbral dado\n",
    "    \n",
    "    Arguments:\n",
    "        X: DF input\n",
    "        Action: Fit o Fit_Transform\n",
    "        umbral: umbral para los autovalores conservados al hacer transform\n",
    "        \n",
    "    Returns:\n",
    "        X_train_out : train input \n",
    "        X_test_out: test input \n",
    "    '''\n",
    "    if(Action=='Fit'):\n",
    "        nf = X.shape[1]\n",
    "        pca = PCA(n_components=nf)\n",
    "        pca.fit(X)\n",
    "        print(pca.singular_values_)\n",
    "    if(Action=='Fit_Transform'):\n",
    "        nf = X.shape[1]\n",
    "        pca = PCA(n_components=nf)\n",
    "        pca.fit(X)\n",
    "        n=np.sum(pca.singular_values_>umbral)\n",
    "        pca = PCA(n_components=n)\n",
    "        pca.fit(X)\n",
    "        X_new=pca.transform(X)\n",
    "        X_t_new=pca.transform(X_t)\n",
    "        return X_new,X_t_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961b8a21",
   "metadata": {},
   "source": [
    "### Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25f974fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standarizador_normal:\n",
    "    '''\n",
    "    Standarizador estandar.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.std =  {}\n",
    "        self.mean = {}\n",
    "    \n",
    "    def fit(self,X,name):\n",
    "        '''\n",
    "        Calcula media y desviación standar de una feature\n",
    "        \n",
    "        Arguments:\n",
    "            X: DataFrame input\n",
    "            name: feature name\n",
    "        '''\n",
    "        self.mean[name]=np.mean(X[name])\n",
    "        self.std[name]=np.std(X[name])\n",
    "\n",
    "    def transform(self,X,name):\n",
    "        '''\n",
    "        transforma una feature\n",
    "        \n",
    "        Arguments:\n",
    "            X: DataFrame input\n",
    "            name: feature name\n",
    "            \n",
    "        Return:\n",
    "            transformed output\n",
    "        '''\n",
    "        X[name]=(X[name]- self.mean[name])/self.std[name]\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a0bd9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standarizador:\n",
    "    '''\n",
    "    Standarizador especial para operar sobre todas las columnas históricas de un tipo, al mismo tiempo.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.std =  {}\n",
    "        self.mean = {}\n",
    "    \n",
    "    def fit(self,X,name):\n",
    "        '''\n",
    "        Calcula media y desviación standar de una feature\n",
    "        \n",
    "        Arguments:\n",
    "            X: input\n",
    "            name: feature name\n",
    "        '''\n",
    "        self.mean[name]=np.mean(X.values)\n",
    "        self.std[name]=np.std(X.values)\n",
    "\n",
    "    def transform(self,X,name):\n",
    "        '''\n",
    "        transforma una feature\n",
    "        \n",
    "        Arguments:\n",
    "            X: input\n",
    "            name: feature name\n",
    "            \n",
    "        Return:\n",
    "            transformed output\n",
    "            \n",
    "        '''\n",
    "        return (X- self.mean[name])/self.std[name]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5df6fa5",
   "metadata": {},
   "source": [
    "## MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e70a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2677421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Dropout ,concatenate,LSTM, Reshape\n",
    "\n",
    "from tensorflow.keras import metrics, Input, Model\n",
    "\n",
    "from tensorflow.keras import losses, optimizers \n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1aee8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_all_models():\n",
    "    '''\n",
    "    Borra todos los modelos de la memoria\n",
    "    '''\n",
    "    clear_session()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cfd042",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "964d13db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_Validation_RandomForest(Grid,X,y,k=7):\n",
    "    \n",
    "    '''\n",
    "    Hace un cross validation para un Random Forest\n",
    "    \n",
    "    Arguments:\n",
    "        Grid= grid de parametros para probar\n",
    "        X= Train input\n",
    "        y= Train output\n",
    "        k= orden del K-fold cross validation (numeor de splits)\n",
    "        \n",
    "    Returns:\n",
    "        Hiper-parametros optimos\n",
    "    '''\n",
    "    forest_clas = RandomForestClassifier(random_state=42,n_jobs=4)\n",
    "    \n",
    "    grid_search = GridSearchCV(forest_clas, Grid, cv=k,scoring='accuracy',return_train_score=True,verbose=4)\n",
    "    \n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    print(\"Scorer\")\n",
    "    print(grid_search.scorer_)\n",
    "    print(\"Best Score\")\n",
    "    print(grid_search.best_score_)\n",
    "    print(\"the best trained model:\")\n",
    "    print(grid_search.best_estimator_)\n",
    "    \n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99570ad",
   "metadata": {},
   "source": [
    "### Red Neuronal Densa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e58c043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_NN(output_units,hidden_units,activation,drop_out,input_shape,met):\n",
    "    '''\n",
    "    Crea una red neuronal densa\n",
    "    \n",
    "    Arguments:\n",
    "        output_units: output shape\n",
    "        hidden_units: numero de nodos en cada layer\n",
    "        activation: lista con las funciones de activacion de las layers\n",
    "        drop_out: lista con los dropout de las layers\n",
    "        input_shape: tamaño del input (numero de features o columnas)\n",
    "        met: metricas\n",
    "\n",
    "        \n",
    "    Returns:\n",
    "        model: modelo \n",
    "    '''\n",
    "    model = Sequential()\n",
    "    N=np.arange(len(hidden_units))\n",
    "    for h,a,d,i in zip(hidden_units,activation,drop_out,N):\n",
    "        if(i==0):\n",
    "            model.add(Dense(h, activation=a, input_shape=(input_shape,)))\n",
    "        else:\n",
    "            model.add(Dense(h, activation=a))\n",
    "        if(d>0):\n",
    "            model.add(Dropout(d))\n",
    "    model.add(Dense(output_units, activation='softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    adam = optimizers.Adam(learning_rate=2*10**-4)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer= adam, metrics=met)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d4ca56",
   "metadata": {},
   "source": [
    "### Modelo Red Recurrente Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "727467ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_RNN(hidden_units_RNN,hidden_units_dense_extra, activation_dense_extra,drop_out, output_units, input_shape,met):\n",
    "    '''\n",
    "    Crea una red neuronal recurrente simple\n",
    "    \n",
    "    Arguments:\n",
    "        hidden_units_RNN: layers recurrentes\n",
    "        hidden_units_dense_extra: layers densas\n",
    "        activation_dense_extra: lista con las funciones de activación de las layers densas\n",
    "        drop_out: lista con los dropout de las layers densas\n",
    "        output_units: dimensiones del output\n",
    "        input_shape: (time_steps,predictors)\n",
    "        met: metricas\n",
    "        \n",
    "    Returns:\n",
    "        model: modelo \n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(hidden_units_RNN, input_shape=input_shape, dropout=0.1, recurrent_dropout=0.1)) #,activation=activation[0]\n",
    "    \n",
    "    for h,a,d in zip(hidden_units_dense_extra,activation_dense_extra,drop_out):\n",
    "        model.add(Dense(h, activation=a))\n",
    "        if(d>0):\n",
    "            model.add(Dropout(d))\n",
    "            \n",
    "    model.add(Dense(units=output_units, activation=\"softmax\"))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    adam = optimizers.Adam(learning_rate=2*10**-4)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam,metrics=met)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb65ef8",
   "metadata": {},
   "source": [
    "### Modelo Red Recurrente Long short-term memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ed431e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LSTM(hidden_units_RNN,hidden_units_dense_extra, activation_dense_extra,drop_out, output_units, input_shape,met):\n",
    "    '''\n",
    "    Crea una red neuronal recurrente Long short-term memory\n",
    "    \n",
    "    Arguments:\n",
    "        hidden_units_RNN: layers recurrentes\n",
    "        hidden_units_dense_extra: layers densas\n",
    "        activation_dense_extra: lista con las funciones de activación de las layers densas\n",
    "        drop_out: lista con los dropout de las layers densas\n",
    "        output_units: dimensiones del output\n",
    "        input_shape: (time_steps,predictors)\n",
    "        met: metricas\n",
    "        \n",
    "    Returns:\n",
    "        model: modelo \n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hidden_units_RNN, input_shape=input_shape, dropout=0.1, recurrent_dropout=0.1)) #,activation=activation[0]\n",
    "    \n",
    "    for h,a,d in zip(hidden_units_dense_extra,activation_dense_extra,drop_out):\n",
    "        model.add(Dense(h, activation=a))\n",
    "        if(d>0):\n",
    "            model.add(Dropout(d))\n",
    "            \n",
    "    model.add(Dense(units=output_units, activation=\"softmax\"))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    adam = optimizers.Adam(learning_rate=2*10**-4)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam,metrics=met)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd77752",
   "metadata": {},
   "source": [
    "### Modelo Mixto (RNN + Denso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4aee4998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Mix_Model(tipo_RNN ,recurrent_units, dense_units,dense_drop_out, out_shape, input_shape_history,input_shape_now,met):\n",
    "    '''\n",
    "    Crea una red mixta que consta de dos capas recurrentes para tratar los datos temporales de cada equipo y una capa densa donde \n",
    "    se ingresan los outputs de esas capas recurrentes + se agregan datos referentes al partido a modelar.\n",
    "    \n",
    "    Arguments:\n",
    "        tipo_RNN: Tipo de red recurrente LSTM o Simple\n",
    "        recurrent_units: layers de la capa recurrente\n",
    "        dense_units: lista de numero de nodos de la capa densa\n",
    "        dense_drop_out: porcentage de drop out para regularizar\n",
    "        out_shape: shape del output (target)\n",
    "        input_shape_history: shape de los inputs de las capas recurrentes (time_steps,predictors)\n",
    "        input_shape_now: shape de los inputs de la capa densa\n",
    "        met: metricas a evaluar\n",
    "        \n",
    "    Returns:\n",
    "        model: modelo \n",
    "    '''\n",
    "    \n",
    "    # define two sets of inputs\n",
    "    a = Input(shape=input_shape_history)\n",
    "    b = Input(shape=input_shape_history)\n",
    "    c = Input(shape=(input_shape_now,))\n",
    "    \n",
    "    # the first branch operates on the first input\n",
    "    if(tipo_RNN=='Simple'):\n",
    "        m1 = SimpleRNN(recurrent_units, input_shape=input_shape_history, dropout=0.1, recurrent_dropout=0,use_bias=False,unroll=False,return_sequences=True,return_state=False)(a)\n",
    "        m2 = SimpleRNN(recurrent_units, input_shape=input_shape_history, dropout=0.1, recurrent_dropout=0,use_bias=False,unroll=False,return_sequences=True,return_state=False)(b)\n",
    "    elif(tipo_RNN=='LSTM'):\n",
    "        m1 = LSTM(recurrent_units, input_shape=input_shape_history, dropout=0.1, recurrent_dropout=0,use_bias=False,unroll=True,return_sequences=True,return_state=False)(a)\n",
    "        m2 = LSTM(recurrent_units, input_shape=input_shape_history, dropout=0.1, recurrent_dropout=0,use_bias=False,unroll=True,return_sequences=True,return_state=False)(b)\n",
    "\n",
    "\n",
    "    M1=Reshape((input_shape_history[0]*recurrent_units,), input_shape=input_shape_history)(m1)\n",
    "    M2=Reshape((input_shape_history[0]*recurrent_units,), input_shape=input_shape_history)(m2)\n",
    "    \n",
    "    # combine the output of the three branches\n",
    "    M = concatenate([M1,M2,c])\n",
    "    \n",
    "    z = Dense(units=dense_units[0], activation='relu')(M)\n",
    "    z = Dropout(dense_drop_out)(z)\n",
    "    z = Dense(units=dense_units[1], activation='relu')(z)\n",
    "    z = Dropout(dense_drop_out)(z)\n",
    "    z = Dense(units=dense_units[2], activation='relu')(z)\n",
    "    z = Dropout(dense_drop_out)(z)\n",
    "    z = Dense(units=dense_units[3], activation='relu')(z)\n",
    "    z = Dropout(dense_drop_out)(z)\n",
    "    z = Dense(units=dense_units[4], activation='relu')(z)\n",
    "    z = Dense(units=out_shape, activation=\"softmax\")(z)\n",
    "\n",
    "    \n",
    "    # our model will accept the inputs of the two branches and\n",
    "    # then output a single value\n",
    "    model = Model(inputs=[a, b, c], outputs=z,name='Modelo_IFA')\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    adam = optimizers.Adam(learning_rate=1*10**-4)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam,metrics=met)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d025539",
   "metadata": {},
   "source": [
    "## ANALISIS DE LOS RESULTADOS DE LOS MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c9ff091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3338e9e2",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee4bd16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_to_vect(y_l,y_p):\n",
    "    '''\n",
    "    Compara target con predicción\n",
    "    Devuelve un diccionario con el \"accuracy\" y otra metrica más\n",
    "    \n",
    "    Arguments:\n",
    "        y_1: target\n",
    "        y_p: output de probabilidades\n",
    "\n",
    "    Return:\n",
    "        R: diccionario con resultados\n",
    "\n",
    "    '''\n",
    "    R={}\n",
    "    y2=from_prob_to_outcome(y_p)\n",
    "    y11=np.array(y_l)\n",
    "    y22=np.array(y2)\n",
    "    y33=np.array(y_p)\n",
    "    s=0\n",
    "    l=len(y11)\n",
    "    for i in range(l):\n",
    "        s=s+np.sum(np.abs(y11[i]-y22[i]))/2\n",
    "    R['Acc']=(l-s,(l-s)/l)\n",
    "    s=0\n",
    "    for i in range(l):\n",
    "        s=s+np.sum(np.abs(y11[i]-y33[i]))\n",
    "        #s=s+np.sqrt(np.sum((y11[i]-y33[i])**2))\n",
    "    R['Abs_mean_distance']=s/l\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "39daa089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(y,y_p,y_t,y_t_p):\n",
    "    '''\n",
    "    Calcula accuracy y otra metrica para el train y test, y lo imprime por pantalla\n",
    "    \n",
    "    Arguments:\n",
    "        y: target train\n",
    "        y_p: predicciones train\n",
    "        y_t: target test\n",
    "        y_t_p: predicciones test\n",
    "\n",
    "    '''\n",
    "    print('ACCURACY\\n')\n",
    "    print('Train:')\n",
    "    print(compare_to_vect(y,y_p))\n",
    "    print('Test:')\n",
    "    print(compare_to_vect(y_t,y_t_p))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5aa7161e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def draw_confusion(y,y_p,y_t,y_t_p):\n",
    "    '''\n",
    "    Imprime matrix de confusion\n",
    "    \n",
    "    Arguments:\n",
    "        y: target train\n",
    "        y_p: predicciones train\n",
    "        y_t: target test\n",
    "        y_t_p: predicciones test\n",
    "\n",
    "    '''\n",
    "    labels=labels_confusion_matrix(y)    \n",
    "    fig, axs = plt.subplots(nrows = 1,ncols = 2)\n",
    "    for title,yy,yy_p,a in zip(['Train','Test'],[y,y_t],[y_p,y_t_p],axs):\n",
    "    \n",
    "        y_hat = from_prob_to_outcome(yy_p)\n",
    "        y_hat_class = np.argmax(y_hat, axis = 1)\n",
    "        y_class = np.argmax(np.array(yy), axis = 1)\n",
    "        \n",
    "        cm = metrics.confusion_matrix(y_class, y_hat_class)\n",
    "         \n",
    "        a.matshow(cm)\n",
    "        \n",
    "        a.set_title('Confusion Matrix '+title,size=15)\n",
    "        a.set_xticklabels([''] + labels, size=15)\n",
    "        a.set_yticklabels([''] + labels, size=15)\n",
    "        a.set_ylabel('Predicted',size=15)\n",
    "        a.set_xlabel('True',size=15)\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                a.text(i, j, cm[i,j], va='center', ha='center',color='white',size=20)\n",
    "    fig.set_size_inches(10,10)\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "28b99eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_metric_Model(history):\n",
    "    '''\n",
    "    Plotea loss y accuracy en funcion del epoch\n",
    "    \n",
    "    Arguments:\n",
    "        history: return del fit de modelo\n",
    "\n",
    "    '''\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20,4))\n",
    "    \n",
    "    metric=['loss','accuracy']    \n",
    "    pos=[\"upper right\",\"upper left\"]\n",
    "    for a,m,p in zip(ax,metric,pos):\n",
    "        a.plot(history.history[m], '-o',label='Training data')\n",
    "        a.plot(history.history['val_'+m],'-o', label='Validation data')\n",
    "        a.set_title('Training Evolution - '+m,fontsize=16)\n",
    "        a.set_ylabel('Value',fontsize=14)\n",
    "        a.set_xlabel('No. epoch',fontsize=14)\n",
    "        a.legend(loc=p)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baf220c",
   "metadata": {},
   "source": [
    "### Tablas de Reporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "675fcc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Report_RF_results(model,model_name,X,y,X_t,y_t,Rep):\n",
    "    '''\n",
    "    Realiza un reporte del RF\n",
    "    \n",
    "    Arguments:\n",
    "        model: RF trained model\n",
    "        model_name: nombre especifico de ese modelo\n",
    "        X: train input\n",
    "        y: train target\n",
    "        X_t: test input\n",
    "        y_t: test target\n",
    "        Rep: Dict donde llenar el reporte\n",
    "    \n",
    "    Returns:\n",
    "        Rep: Dict de reporte\n",
    "    '''\n",
    "    \n",
    "    y_p=model.predict(X)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Rep['Nombre'].append(model_name+' Train')\n",
    "    Rep['Accuracy'].append(model.score(X,y))\n",
    "    Rep['F1_macro'].append(metrics.f1_score(y,y_p,average='macro'))\n",
    "    #Rep['AUC'].append(metrics.roc_auc_score(y,y_p))\n",
    "    \n",
    "    y_p=model.predict(X_t)\n",
    "    \n",
    "    \n",
    "    Rep['Nombre'].append(model_name+' Test')\n",
    "    Rep['Accuracy'].append(model.score(X_t,y_t))\n",
    "    Rep['F1_macro'].append(metrics.f1_score(y_t,y_p,average='macro'))\n",
    "    #Rep['AUC'].append(metrics.roc_auc_score(y,y_p))\n",
    "    \n",
    "    display(pd.DataFrame(Rep))\n",
    "                               \n",
    "    return Rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "984a15f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Print_Report(y, y_pred,y_t, y_t_pred):\n",
    "    '''\n",
    "    Imprime reporte de metricas para el train y test\n",
    "    \n",
    "    Arguments:\n",
    "        y: target train\n",
    "        y_pred: predicciones train\n",
    "        y_t: target test\n",
    "        y_t_pred: predicciones test\n",
    "\n",
    "    '''\n",
    "    ll=labels_confusion_matrix(y)\n",
    "    \n",
    "    l_train=[l+'_train' for l in ll]\n",
    "    y_hat = from_prob_to_outcome(y_pred)\n",
    "    Tr=metrics.classification_report(y,y_hat, output_dict=True,target_names=l_train)\n",
    "    Tr=pd.DataFrame(Tr)\n",
    "\n",
    "    l_test=[l+'_test' for l in ll]\n",
    "    y_hat = from_prob_to_outcome(y_t_pred)\n",
    "    Te=metrics.classification_report(y_t,y_hat, output_dict=True,target_names=l_test)\n",
    "    Te=pd.DataFrame(Te)\n",
    "    \n",
    "    display(Tr)\n",
    "    display(Te)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c222d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Append_line_to_report_table(DF,diccionario,name,RNN,partidos,N_Features_h,N_Features_m):\n",
    "    '''\n",
    "    Agrega una linea al reporte de resultados\n",
    "    \n",
    "    Arguments:\n",
    "        DF: DataFrame de reporte\n",
    "        diccionario: diccionario con resultados de un modelo\n",
    "        name: nombre del modelo al que corresponden los resultados\n",
    "        RNN: tipo de red neuronal recurrente utilizada\n",
    "        partidos: número de partidos considerados\n",
    "        N_Features_h: número de variables por partido del historial consideradas\n",
    "        N_Features_m: número de variables referentes al partido a modelar consideradas.\n",
    "    \n",
    "    Returns:\n",
    "        DF: Reporte con la linea nueva anexada\n",
    "    '''\n",
    "    diccionario['Partidos Considerados']=partidos\n",
    "    diccionario['RNN']=RNN\n",
    "    diccionario['N_Features_m']=N_Features_m\n",
    "    diccionario['N_Features_h']=N_Features_h\n",
    "    new_line=pd.DataFrame(diccionario, index=[name,])\n",
    "    DF=DF.append(new_line)\n",
    "    display(DF)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044d97b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Append_line_to_report_table_2(DF,diccionario,name,RNN,partidos,N_Features_h,N_Features_m,batch_size):\n",
    "    '''\n",
    "    Agrega una linea al reporte de resultados\n",
    "    \n",
    "    Arguments:\n",
    "        DF: DataFrame de reporte\n",
    "        diccionario: diccionario con resultados de un modelo\n",
    "        name: nombre del modelo al que corresponden los resultados\n",
    "        RNN: tipo de red neuronal recurrente utilizada\n",
    "        partidos: número de partidos considerados\n",
    "        N_Features_h: número de variables por partido del historial consideradas\n",
    "        N_Features_m: número de variables referentes al partido a modelar consideradas.\n",
    "        batch_size: Número de muestras que se pasan al modelo por iteración de aprendizaje\n",
    "    \n",
    "    Returns:\n",
    "        DF: Reporte con la linea nueva anexada\n",
    "    '''\n",
    "    diccionario['Partidos Considerados']=partidos\n",
    "    diccionario['RNN']=RNN\n",
    "    diccionario['N_Features_m']=N_Features_m\n",
    "    diccionario['N_Features_h']=N_Features_h\n",
    "    diccionario['Batch_size']=batch_size\n",
    "    new_line=pd.DataFrame(diccionario, index=[name,])\n",
    "    DF=DF.append(new_line)\n",
    "    display(DF)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "76064825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_report_table(DF,columna,Y_label,RNN,N_h,N_m):\n",
    "    '''\n",
    "    Realiza un grafico de una columna del dataframe vs un X pasado por variable\n",
    "    \n",
    "    Arguments:\n",
    "        DF: DataFrame de reporte\n",
    "        columna: Y del plot\n",
    "        Y_label: nombre de Y\n",
    "        RNN: lista de tipos de RNN a graficar\n",
    "        N_h: lista de numero de parámetros históricos a considerar\n",
    "        N_m: lista de numero de parámetros del partido a considerar\n",
    "    '''\n",
    "    plt.figure(figsize=(8, 6), dpi=100)\n",
    "    for r in RNN:\n",
    "        for h in N_h:\n",
    "            for m in N_m:  \n",
    "                lab='Tipo de RNN: '+r+r',  # V x $P_h$: '+str(h)+r',  # V x $P_m$: '+str(m)\n",
    "                if(r=='Simple'):\n",
    "                    mark='-s'\n",
    "                elif(r=='LSTM'):\n",
    "                    mark='-o'\n",
    "                plt.plot(DF['Partidos Considerados'][(DF['RNN']==r) & ((DF['N_Features_h']==h) & (DF['N_Features_m']==m))],DF[columna][(DF['RNN']==r) & ((DF['N_Features_h']==h) & (DF['N_Features_m']==m))],mark, label= lab)\n",
    "    plt.xlabel('Numero de partidos considerados',fontsize=14)\n",
    "    plt.ylabel(Y_label,fontsize=14)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d849d93",
   "metadata": {},
   "source": [
    "### Otros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "37380121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def Full_train_and_Report(model,X_train,y_train,X_test,y_test,batch_size,epochs,validation_split,num_classes=3,history_plot=True,confusion_matrix=True,Report_print=True):\n",
    "    '''\n",
    "    Entrena un modelo y reporta el resultado\n",
    "    \n",
    "    Arguments:\n",
    "        model: Modelo\n",
    "        X_train: train input\n",
    "        y_train: train target\n",
    "        X_test: test input\n",
    "        y_test: test target\n",
    "        batch_size: batch size\n",
    "        epochs: epochs\n",
    "        validation_split: tamaño set de validacion\n",
    "        num_classes: numero de clases en el target\n",
    "        history_plot: bool , graficar evolucion del training\n",
    "        confusion_matrix: bool, graficar matrix de confusion\n",
    "        Report_print: bool, imprimir reporte de test y train\n",
    "    \n",
    "    Returns:\n",
    "        y_prediction_train: train prediction\n",
    "        y_prediction_test: test prediction\n",
    "        D: Diccionario con un reporte de resutados\n",
    "    '''\n",
    "    cb=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)]\n",
    "    history = model.fit(X_train, y_train, epochs = epochs , shuffle=True , batch_size = batch_size,  verbose=1, validation_split=validation_split, callbacks=cb)\n",
    "    \n",
    "    if(history_plot):\n",
    "        Plot_metric_Model(history)\n",
    "    \n",
    "    y_prediction_train=model.predict(X_train)\n",
    "    y_prediction_test=model.predict(X_test)\n",
    "    \n",
    "    if(confusion_matrix):\n",
    "        draw_confusion(y_train,y_prediction_train,y_test,y_prediction_test)\n",
    "    if(Report_print):\n",
    "        Print_Report(y_train,y_prediction_train,y_test,y_prediction_test)\n",
    "    \n",
    "    D={}\n",
    "    for m in model.metrics:\n",
    "        name=m.name\n",
    "        D[name+' train']=m(y_train,y_prediction_train).numpy()\n",
    "        D[name+' test']=m(y_test,y_prediction_test).numpy()\n",
    "        \n",
    "    return  y_prediction_train, y_prediction_test,D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e6fb88",
   "metadata": {},
   "source": [
    "### Auxiliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce45d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_confusion_matrix(y):\n",
    "    '''\n",
    "    Genera lista de las clases del target ordenadas\n",
    "    \n",
    "    Arguments:\n",
    "        y: target train\n",
    "    \n",
    "    Returns:\n",
    "        labels: lista de labels\n",
    "    '''\n",
    "    labels=[]\n",
    "    D={'EqA_Derrota':'Eq_B_win','EqA_Empate':'Empate','EqA_Victoria':'Eq_A_win'}\n",
    "    for l in list(y.columns):\n",
    "        labels.append(D[l])\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a139d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_prob_to_outcome(y_p):\n",
    "    '''\n",
    "    transforma output de probabilidades en output de outcomes\n",
    "        \n",
    "    Arguments:\n",
    "        y_p: output de probabilidades\n",
    "\n",
    "    Return:\n",
    "        y_outcome: output de outcomes\n",
    "\n",
    "    '''\n",
    "    y_outcome=(y_p-np.max(y_p,axis=1).reshape(len(y_p),1)==0)*1\n",
    "    return y_outcome"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
